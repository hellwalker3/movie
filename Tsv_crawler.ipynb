{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.crawler.base_crawler import BaseCrawler\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import re\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tsv_dataにtsvをpdで取り出します. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u00445/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/u00445/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "class Tsv_Crawler(BaseCrawler):\n",
    "    def __init__(self,last=0,di=\"data/Tsv_data\"):\n",
    "        super().__init__()\n",
    "        self.di=di\n",
    "        self.file_name=[\"name.basics.tsv.gz\",\"title.akas.tsv.gz\",\"title.basics.tsv.gz\",\"title.crew.tsv.gz\",\"title.episode.tsv.gz\",\"title.principals.tsv.gz\",\"title.ratings.tsv.gz\"]\n",
    "        self.full_load(last)\n",
    "        self.title_connect()\n",
    "    \n",
    "    def download_Tsv(self,url):      \n",
    "        filename = url.split(\"/\")[-1]\n",
    "        with open(self.di+\"/\"+filename, \"wb\") as f:\n",
    "            r = requests.get(url)\n",
    "            f.write(r.content)\n",
    "        print(\"success download from \"+url)\n",
    "        \n",
    "    def full_download_Tsv(self):\n",
    "        try:\n",
    "            os.makedirs(self.di)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        \n",
    "        test_url = 'https://datasets.imdbws.com'\n",
    "        res = self.get_response(test_url)\n",
    "        soup = BeautifulSoup(markup=res.content, features='html.parser')\n",
    "        for tr in soup.find_all(\"a\"):\n",
    "            Tsv_url=tr.get('href')\n",
    "            if re.search(\".tsv.gz\",Tsv_url):\n",
    "                self.download_Tsv(Tsv_url)\n",
    "    \n",
    "                  \n",
    "    def load_Tsv_as_pd(self,file):\n",
    "        df=pd.read_table(self.di+\"/\"+file,index_col=0)\n",
    "        #実行速度上げる用nrows=60000\n",
    "        return df\n",
    "    \n",
    "    def elminate_double(self):\n",
    "        self.full_pd[1]=self.full_pd[1][self.full_pd[1][\"ordering\"]==1]\n",
    "        self.full_pd[5]=self.full_pd[5][self.full_pd[5][\"ordering\"]==1]\n",
    "        self.full_pd[1]=self.full_pd[1].drop(columns='ordering')\n",
    "        self.full_pd[5]=self.full_pd[5].drop(columns='ordering')\n",
    "        \n",
    "    \n",
    "    def split_pd(self,last):\n",
    "        for i in range(len(self.full_pd)):\n",
    "            if i>=1:\n",
    "                self.full_pd[i]=self.full_pd[i][self.full_pd[i].index.str[2:].astype(int)<=last]\n",
    "            \n",
    "    \n",
    "    def full_load(self,last):\n",
    "        self.full_pd=[]\n",
    "        if not os.path.exists(self.di):\n",
    "            self.full_download_Tsv()\n",
    "        for name in self.file_name:\n",
    "            self.full_pd.append(self.load_Tsv_as_pd(name))\n",
    "        \n",
    "        self.elminate_double()\n",
    "        #最後のid指定\n",
    "        #self.split_pd(last)\n",
    "\n",
    "                \n",
    "    def load_title(self):\n",
    "        self.title=pd.read_table(self.di+\"/title.csv\",index_col=0)\n",
    "\n",
    "    \n",
    "    def title_connect(self):\n",
    "        c=0\n",
    "        for pa in self.full_pd:\n",
    "            c+=1\n",
    "            if c==2:\n",
    "                df=pa\n",
    "            elif c>=3:\n",
    "                df=df.join(pa ,how='outer')\n",
    "        self.title=df\n",
    "        self.title.to_csv(self.di+\"/title.csv\")\n",
    "    \n",
    "        \n",
    "Tsv = Tsv_Crawler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tsv.title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "#target_histogram\n",
    "\n",
    "def split_count(pand):\n",
    "    count={}\n",
    "    for i in range(len(pand)):\n",
    "        if not pd.isna(pand[i]):\n",
    "            genre=pand[i].split(\",\")\n",
    "            for g in genre:\n",
    "                if g in count:\n",
    "                    count[g]+=1\n",
    "                else:\n",
    "                    count[g]=1\n",
    "    return pd.Series(count)\n",
    "        \n",
    "\n",
    "columns_labels=['region', 'language' ,'types' ,'attributes', 'isOriginalTitle', 'titleType',\n",
    "  'isAdult', 'startYear' ,'endYear',\n",
    " 'runtimeMinutes' ,'genres',\n",
    " 'seasonNumber' ,'category','job', \n",
    " 'averageRating' ,'numVotes']\n",
    "split=['genres']\n",
    "hist=['averageRating' ,'numVotes']\n",
    "\n",
    "\n",
    "N=len(columns_labels)\n",
    "ncols=1\n",
    "nrows=math.ceil(N/1)\n",
    "fig, axes = plt.subplots(nrows,ncols,figsize=(20,6*nrows))\n",
    "for ax,la in zip(axes.flat, columns_labels):\n",
    "    if la in hist:\n",
    "        ax.hist(Tsv.title[la])\n",
    "    else:\n",
    "        if la in split:\n",
    "            c=split_count(Tsv.title[la])\n",
    "        else:\n",
    "            c=Tsv.title[la].value_counts()\n",
    "        ax.bar(c.index,c.values)\n",
    "    ax.set_xlabel(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
